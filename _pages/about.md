---
layout: about
title: about
permalink: /
subtitle: Math and ML.  Trying to understand neural networks better.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular

news: true # includes a list of news items
latest_posts: true # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I am currently a postdoctoral research fellow at New York University working with [Yann LeCun](https://research.facebook.com/people/lecun-yann/) and [Andrew Gordon Wilson](https://cims.nyu.edu/~andrewgw/). My research focuses on both applied and fundamental problems in machine learning:  

1.  **Safe and reasonable AI** - ​​Modern AI systems contain biases, security vulnerabilities, expose users to privacy breaches, and exhibit catastrophic failures of reasoning and generalization.  My work aims to detect and close these gaps.  

2.  **Mathematical and computational tools for understanding and improving neural networks** - Despite rapid advances in capabilities, our understanding of why neural networks work is highly limited.  My research focuses on the structures in neural networks and their training procedures that enable them to generalize in practice.  

My portfolio includes award winning work in Bayesian inference, generalization theory, algorithmic reasoning, and AI security and privacy.  Our recent paper on model comparison received the Outstanding Paper Award at ICML 2022.  Before my current position, I received a Ph.D. in mathematics at the University of Maryland where I worked with [Tom Goldstein](https://www.cs.umd.edu/~tomg/) and [Wojciech Czaja](https://www.math.umd.edu/~czaja/).  Since 2020, 46 of my papers have been accepted at top CS venues (NeurIPS, ICML, ICLR, CVPR, AAAI, and TPAMI).
