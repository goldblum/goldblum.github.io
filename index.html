<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Micah Goldblum </title> <meta name="author" content="Micah Goldblum"> <meta name="description" content="Micah Goldblum. Math and ML. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://goldblum.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/website_cv.pdf">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Micah</span> Goldblum </h1> <p class="desc">Math and ML. Trying to understand neural networks better.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/prof_pic.jpg?42094d1f6a2dd5b732cd394337aad931" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>goldblum[at]nyu[dot]edu</p> <a href="https://scholar.google.com/citations?user=pGDKzuUAAAAJ" rel="external nofollow noopener" target="_blank">Google Scholar</a> </div> </div> <div class="clearfix"> <p>I am currently a postdoctoral research fellow at New York University working with <a href="https://research.facebook.com/people/lecun-yann/" rel="external nofollow noopener" target="_blank">Yann LeCun</a> and <a href="https://cims.nyu.edu/~andrewgw/" rel="external nofollow noopener" target="_blank">Andrew Gordon Wilson</a>. My research focuses on both applied and fundamental problems in machine learning:</p> <ol> <li> <p><strong>Safe and reasonable AI</strong> - Modern AI systems contain biases, security vulnerabilities, expose users to privacy breaches, and exhibit catastrophic failures of reasoning and generalization. My work aims to detect and close these gaps.</p> </li> <li> <p><strong>Mathematical and computational tools for understanding and improving neural networks</strong> - Despite rapid advances in capabilities, our understanding of why neural networks work is highly limited. My research focuses on the structures in neural networks and their training procedures that enable them to generalize in practice.</p> </li> </ol> <p>My portfolio includes award winning work in Bayesian inference, generalization theory, algorithmic reasoning, and AI security and privacy. Our recent paper on model comparison received the Outstanding Paper Award at ICML 2022. Before my current position, I received a Ph.D. in mathematics at the University of Maryland where I worked with <a href="https://www.cs.umd.edu/~tomg/" rel="external nofollow noopener" target="_blank">Tom Goldstein</a> and <a href="https://www.math.umd.edu/~czaja/" rel="external nofollow noopener" target="_blank">Wojciech Czaja</a>. Since 2020, 49 of my papers have been accepted at top CS venues (NeurIPS, ICML, ICLR, CVPR, AAAI, and TPAMI).</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Sep 21, 2023</th> <td> 9 papers accepted to NeurIPS 2023 </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 20, 2023</th> <td> 8 papers accepted to ICLR 2023 </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 14, 2022</th> <td> 7 papers accepted to NeurIPS 2022 </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 17, 2022</th> <td> <a href="https://icml.cc/virtual/2022/poster/17991" rel="external nofollow noopener" target="_blank">Outstanding Paper Award</a> at ICML 2022 </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/backbone-480.webp 480w,/assets/img/publication_preview/backbone-800.webp 800w,/assets/img/publication_preview/backbone-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/backbone.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="backbone.jpeg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="goldblum2023battle" class="col-sm-8"> <div class="title">Battle of the Backbones: A Large-Scale Comparison of Pretrained Models across Computer Vision Tasks</div> <div class="author"> <em>Micah Goldblum</em> ,  Hossein Souri ,  Renkun Ni Ni ,  Manli Shu ,  Viraj Uday Prabhu ,  Gowthami Somepalli ,  Prithvijit Chattopadhyay ,  Adrien Bardes ,  Mark Ibrahim ,  Judy Hoffman ,  Rama Chellappa ,  Andrew Gordon Wilson ,  and  Tom Goldstein </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2310.19909" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Neural network based computer vision systems are typically built on a backbone, a pretrained or randomly initialized feature extractor. Several years ago, the default option was an ImageNet-trained convolutional neural network. However, the recent past has seen the emergence of countless backbones pretrained using various algorithms and datasets. While this abundance of choice has led to performance increases for a range of systems, it is difficult for practitioners to make informed decisions about which backbone to choose. Battle of the Backbones (BoB) makes this choice easier by benchmarking a diverse suite of pretrained models, including vision-language models, those trained via self-supervised learning, and the Stable Diffusion backbone, across a diverse set of computer vision tasks ranging from classification to object detection to OOD generalization and more. Furthermore, BoB sheds light on promising directions for the research community to advance computer vision by illuminating strengths and weakness of existing approaches through a comprehensive analysis conducted on more than 1500 training runs. While vision transformers (ViTs) and self-supervised learning (SSL) are increasingly popular, we find that convolutional neural networks pretrained in a supervised fashion on large training sets still perform best on most tasks among the models we consider. Moreover, in apples-to-apples comparisons on the same architectures and similarly sized pretraining datasets, we find that SSL backbones are highly competitive, indicating that future works should perform SSL pretraining with advanced architectures and larger pretraining datasets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/fairfacerec-480.webp 480w,/assets/img/publication_preview/fairfacerec-800.webp 800w,/assets/img/publication_preview/fairfacerec-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/fairfacerec.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="fairfacerec.jpeg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="dooley2023importance" class="col-sm-8"> <div class="title">Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition</div> <div class="author"> Samuel Dooley ,  Rhea Sukthanker ,  John P Dickerson ,  Colin White ,  Frank Hutter ,  and  <em>Micah Goldblum</em> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2210.09943" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race. Conventional wisdom dictates that model biases arise from biased training data. As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition. In our work, we discover that biases are actually inherent to neural network architectures themselves. Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/marginal-480.webp 480w,/assets/img/publication_preview/marginal-800.webp 800w,/assets/img/publication_preview/marginal-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/marginal.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="marginal.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lotfi2022bayesian" class="col-sm-8"> <div class="title">Bayesian Model Selection, the Marginal Likelihood, and Generalization</div> <div class="author"> Sanae Lotfi ,  Pavel Izmailov ,  Gregory Benton ,  <em>Micah Goldblum</em> ,  and  Andrew Gordon Wilson </div> <div class="periodical"> <em>International Conference on Machine Learning (ICML) Outstanding Paper Award</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2202.11678" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>How do we compare between hypotheses that are entirely consistent with observations? The marginal likelihood (aka Bayesian evidence), which represents the probability of generating our observations from a prior, provides a distinctive approach to this foundational question, automatically encoding Occam’s razor. Although it has been observed that the marginal likelihood can overfit and is sensitive to prior assumptions, its limitations for hyperparameter learning and discrete model comparison have not been thoroughly investigated. We first revisit the appealing properties of the marginal likelihood for learning constraints and hypothesis testing. We then highlight the conceptual and practical issues in using the marginal likelihood as a proxy for generalization. Namely, we show how marginal likelihood can be negatively correlated with generalization, with implications for neural architecture search, and can lead to both underfitting and overfitting in hyperparameter learning. We provide a partial remedy through a conditional marginal likelihood, which we show is more aligned with generalization, and practically valuable for large-scale hyperparameter learning, such as in deep kernel learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/colddiffusion-480.webp 480w,/assets/img/publication_preview/colddiffusion-800.webp 800w,/assets/img/publication_preview/colddiffusion-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/colddiffusion.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="colddiffusion.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="bansal2023cold" class="col-sm-8"> <div class="title">Cold Diffusion: Inverting Arbitrary Image Transforms Without Noise</div> <div class="author"> Arpit Bansal ,  Eitan Borgnia ,  Hong-Min Chu ,  Jie S Li ,  Hamid Kazemi ,  Furong Huang ,  <em>Micah Goldblum</em> ,  Jonas Geiping ,  and  Tom Goldstein </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2208.09392" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Standard diffusion models involve an image transform – adding Gaussian noise – and an image restoration operator that inverts this degradation. We observe that the generative behavior of diffusion models is not strongly dependent on the choice of image degradation, and in fact an entire family of generative models can be constructed by varying this choice. Even when using completely deterministic degradations (e.g., blur, masking, and more), the training and test-time update rules that underlie diffusion models can be easily generalized to create generative models. The success of these fully deterministic models calls into question the community’s understanding of diffusion models, which relies on noise in either gradient Langevin dynamics or variational inference, and paves the way for generalized diffusion models that invert arbitrary processes.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/meta-480.webp 480w,/assets/img/publication_preview/meta-800.webp 800w,/assets/img/publication_preview/meta-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/meta.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="meta.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="goldblum2020adversarially1" class="col-sm-8"> <div class="title">Adversarially Robust Few-Shot Learning: A Meta-Learning Approach</div> <div class="author"> <em>Micah Goldblum</em> ,  Liam Fowl ,  and  Tom Goldstein </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/1910.00982" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Previous work on adversarially robust neural networks for image classification requires large training sets and computationally expensive training procedures. On the other hand, few-shot learning methods are highly vulnerable to adversarial examples. The goal of our work is to produce networks which both perform well at few-shot classification tasks and are simultaneously robust to adversarial examples. We develop an algorithm, called Adversarial Querying (AQ), for producing adversarially robust meta-learners, and we thoroughly investigate the causes for adversarial vulnerability. Moreover, our method achieves far superior robust performance on few-shot image classification tasks, such as Mini-ImageNet and CIFAR-FS, than robust transfer learning.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/variance_2-480.webp 480w,/assets/img/publication_preview/variance_2-800.webp 800w,/assets/img/publication_preview/variance_2-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/variance_2.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="variance_2.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="goldblum2020unraveling" class="col-sm-8"> <div class="title">Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks</div> <div class="author"> <em>Micah Goldblum</em> ,  Steven Reich ,  Liam Fowl ,  Renkun Ni ,  Valeriia Cherepanova ,  and  Tom Goldstein </div> <div class="periodical"> <em>International Conference on Machine Learning (ICML)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2002.06753" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Meta-learning algorithms produce feature extractors which achieve state-of-the-art performance on few-shot classification. While the literature is rich with meta-learning methods, little is known about why the resulting feature extractors perform so well. We develop a better understanding of the underlying mechanics of meta-learning and the difference between models trained using meta-learning and models which are trained classically. In doing so, we introduce and verify several hypotheses for why meta-learned models perform better. Furthermore, we develop a regularizer which boosts the performance of standard training routines for few-shot classification. In many cases, our routine outperforms meta-learning while simultaneously running an order of magnitude faster.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/propaganda-480.webp 480w,/assets/img/publication_preview/propaganda-800.webp 800w,/assets/img/publication_preview/propaganda-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/propaganda.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="propaganda.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="goldblum2019truth" class="col-sm-8"> <div class="title">Truth or Backpropaganda? An Empirical Investigation of Deep Learning Theory</div> <div class="author"> <em>Micah Goldblum</em> ,  Jonas Geiping ,  Avi Schwarzschild ,  Michael Moeller ,  and  Tom Goldstein </div> <div class="periodical"> <em>International Conference on Learning Representations (ICLR)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/1910.00359" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>We empirically evaluate common assumptions about neural networks that are widely held by practitioners and theorists alike. In this work, we: (1) prove the widespread existence of suboptimal local minima in the loss landscape of neural networks, and we use our theory to find examples; (2) show that small-norm parameters are not optimal for generalization; (3) demonstrate that ResNets do not conform to wide-network theories, such as the neural tangent kernel, and that the interaction between skip connections and batch normalization plays a role; (4) find that rank does not correlate with generalization or robustness in a practical setting.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/distilled-480.webp 480w,/assets/img/publication_preview/distilled-800.webp 800w,/assets/img/publication_preview/distilled-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/distilled.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="distilled.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="goldblum2020adversarially2" class="col-sm-8"> <div class="title">Adversarially Robust Distillation</div> <div class="author"> <em>Micah Goldblum</em> ,  Liam Fowl ,  Soheil Feizi ,  and  Tom Goldstein </div> <div class="periodical"> <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/1905.09747" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Knowledge distillation is effective for producing small, high-performance neural networks for classification, but these small networks are vulnerable to adversarial attacks. This paper studies how adversarial robustness transfers from teacher to student during knowledge distillation. We find that a large amount of robustness may be inherited by the student even when distilled on only clean images. Second, we introduce Adversarially Robust Distillation (ARD) for distilling robustness onto student networks. In addition to producing small models with high test accuracy like conventional distillation, ARD also passes the superior robustness of large networks onto the student. In our experiments, we find that ARD student models decisively outperform adversarially trained networks of identical architecture in terms of robust accuracy, surpassing state-of-the-art methods on standard robustness benchmarks. Finally, we adapt recent fast adversarial training methods to ARD for accelerated robust distillation.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/deepthink1-480.webp 480w,/assets/img/publication_preview/deepthink1-800.webp 800w,/assets/img/publication_preview/deepthink1-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/deepthink1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="deepthink1.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="schwarzschild2021can" class="col-sm-8"> <div class="title">Can You Learn an Algorithm? Generalizing from Easy to Hard Problems with Recurrent Networks</div> <div class="author"> Avi Schwarzschild ,  Eitan Borgnia ,  Arjun Gupta ,  Furong Huang ,  Uzi Vishkin ,  <em>Micah Goldblum</em> ,  and  Tom Goldstein </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2106.04537" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Deep neural networks are powerful machines for visual pattern recognition, but reasoning tasks that are easy for humans may still be difficult for neural models. Humans possess the ability to extrapolate reasoning strategies learned on simple problems to solve harder examples, often by thinking for longer. For example, a person who has learned to solve small mazes can easily extend the very same search techniques to solve much larger mazes by spending more time. In computers, this behavior is often achieved through the use of algorithms, which scale to arbitrarily hard problem instances at the cost of more computation. In contrast, the sequential computing budget of feed-forward neural networks is limited by their depth, and networks trained on simple problems have no way of extending their reasoning to accommodate harder problems. In this work, we show that recurrent networks trained to solve simple problems with few recurrent steps can indeed solve much more complex problems simply by performing additional recurrences during inference. We demonstrate this algorithmic behavior of recurrent networks on prefix sum computation, mazes, and chess. In all three domains, networks trained on simple problem instances are able to extend their reasoning abilities at test time simply by "thinking for longer."</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/lowkey-480.webp 480w,/assets/img/publication_preview/lowkey-800.webp 800w,/assets/img/publication_preview/lowkey-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/lowkey.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="lowkey.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="cherepanova2021lowkey" class="col-sm-8"> <div class="title">LowKey: Leveraging Adversarial Attacks to Protect Social Media Users from Facial Recognition</div> <div class="author"> Valeriia Cherepanova ,  <em>Micah Goldblum</em> ,  Harrison Foley ,  Shiyuan Duan ,  John P Dickerson ,  Gavin Taylor ,  and  Tom Goldstein </div> <div class="periodical"> <em>International Conference on Learning Representations (ICLR)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2101.07922" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Facial recognition systems are increasingly deployed by private corporations, government agencies, and contractors for consumer services and mass surveillance programs alike. These systems are typically built by scraping social media profiles for user images. Adversarial perturbations have been proposed for bypassing facial recognition systems. However, existing methods fail on full-scale systems and commercial APIs. We develop our own adversarial filter that accounts for the entire image processing pipeline and is demonstrably effective against industrial-grade pipelines that include face detection and large scale databases. Additionally, we release an easy-to-use webtool that significantly degrades the accuracy of Amazon Rekognition and the Microsoft Azure Face Recognition API, reducing the accuracy of each to below 1%.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/manifold-480.webp 480w,/assets/img/publication_preview/manifold-800.webp 800w,/assets/img/publication_preview/manifold-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/manifold.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="manifold.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="pope2021intrinsic" class="col-sm-8"> <div class="title">The Intrinsic Dimension of Images and Its Impact on Learning</div> <div class="author"> Phillip Pope ,  Chen Zhu ,  Ahmed Abdelkader ,  <em>Micah Goldblum</em> ,  and  Tom Goldstein </div> <div class="periodical"> <em>International Conference on Learning Representations (ICLR)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://arxiv.org/abs/2104.08894" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>It is widely believed that natural image data exhibits low-dimensional structure despite the high dimensionality of conventional pixel representations. This idea underlies a common intuition for the remarkable success of deep learning in computer vision. In this work, we apply dimension estimation tools to popular datasets and investigate the role of low-dimensional structure in deep learning. We find that common natural image datasets indeed have very low intrinsic dimension relative to the high number of pixels in the images. Additionally, we find that low dimensional datasets are easier for neural networks to learn, and models solving these tasks generalize better from training to test data. Along the way, we develop a technique for validating our dimension estimation tools on synthetic data generated by GANs allowing us to actively manipulate the intrinsic dimension by controlling the image generation process.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%67%6F%6C%64%62%6C%75%6D@%6E%79%75.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=pGDKzuUAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/micahgoldblum" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Micah Goldblum. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>